{
  "best_metric": 0.1774059236049652,
  "best_model_checkpoint": "./model/checkpoint-600",
  "epoch": 1.0,
  "eval_steps": 100,
  "global_step": 696,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014367816091954023,
      "grad_norm": 1.6930207014083862,
      "learning_rate": 1.971264367816092e-05,
      "loss": 1.3238,
      "step": 10
    },
    {
      "epoch": 0.028735632183908046,
      "grad_norm": 2.501387596130371,
      "learning_rate": 1.942528735632184e-05,
      "loss": 1.1143,
      "step": 20
    },
    {
      "epoch": 0.04310344827586207,
      "grad_norm": 2.3876214027404785,
      "learning_rate": 1.913793103448276e-05,
      "loss": 0.8008,
      "step": 30
    },
    {
      "epoch": 0.05747126436781609,
      "grad_norm": 2.9734995365142822,
      "learning_rate": 1.885057471264368e-05,
      "loss": 0.6042,
      "step": 40
    },
    {
      "epoch": 0.07183908045977011,
      "grad_norm": 3.9029154777526855,
      "learning_rate": 1.8563218390804598e-05,
      "loss": 0.4901,
      "step": 50
    },
    {
      "epoch": 0.08620689655172414,
      "grad_norm": 1.4210121631622314,
      "learning_rate": 1.827586206896552e-05,
      "loss": 0.4022,
      "step": 60
    },
    {
      "epoch": 0.10057471264367816,
      "grad_norm": 2.076216459274292,
      "learning_rate": 1.798850574712644e-05,
      "loss": 0.3536,
      "step": 70
    },
    {
      "epoch": 0.11494252873563218,
      "grad_norm": 2.736734390258789,
      "learning_rate": 1.770114942528736e-05,
      "loss": 0.303,
      "step": 80
    },
    {
      "epoch": 0.12931034482758622,
      "grad_norm": 4.3751373291015625,
      "learning_rate": 1.7413793103448276e-05,
      "loss": 0.3095,
      "step": 90
    },
    {
      "epoch": 0.14367816091954022,
      "grad_norm": 3.3830947875976562,
      "learning_rate": 1.7126436781609197e-05,
      "loss": 0.2886,
      "step": 100
    },
    {
      "epoch": 0.14367816091954022,
      "eval_accuracy": 0.9329257327818737,
      "eval_loss": 0.25858262181282043,
      "eval_runtime": 83.911,
      "eval_samples_per_second": 66.273,
      "eval_steps_per_second": 2.074,
      "step": 100
    },
    {
      "epoch": 0.15804597701149425,
      "grad_norm": 3.2798051834106445,
      "learning_rate": 1.6839080459770115e-05,
      "loss": 0.2914,
      "step": 110
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 2.0256259441375732,
      "learning_rate": 1.6551724137931037e-05,
      "loss": 0.3283,
      "step": 120
    },
    {
      "epoch": 0.1867816091954023,
      "grad_norm": 3.213358163833618,
      "learning_rate": 1.6264367816091955e-05,
      "loss": 0.2531,
      "step": 130
    },
    {
      "epoch": 0.20114942528735633,
      "grad_norm": 4.49527645111084,
      "learning_rate": 1.5977011494252876e-05,
      "loss": 0.3097,
      "step": 140
    },
    {
      "epoch": 0.21551724137931033,
      "grad_norm": 4.162354469299316,
      "learning_rate": 1.5689655172413794e-05,
      "loss": 0.2867,
      "step": 150
    },
    {
      "epoch": 0.22988505747126436,
      "grad_norm": 3.7433977127075195,
      "learning_rate": 1.540229885057471e-05,
      "loss": 0.1842,
      "step": 160
    },
    {
      "epoch": 0.2442528735632184,
      "grad_norm": 2.462959051132202,
      "learning_rate": 1.5114942528735635e-05,
      "loss": 0.1976,
      "step": 170
    },
    {
      "epoch": 0.25862068965517243,
      "grad_norm": 5.171060085296631,
      "learning_rate": 1.4827586206896554e-05,
      "loss": 0.2338,
      "step": 180
    },
    {
      "epoch": 0.27298850574712646,
      "grad_norm": 2.8075199127197266,
      "learning_rate": 1.4540229885057474e-05,
      "loss": 0.2704,
      "step": 190
    },
    {
      "epoch": 0.28735632183908044,
      "grad_norm": 4.3686933517456055,
      "learning_rate": 1.4252873563218392e-05,
      "loss": 0.2904,
      "step": 200
    },
    {
      "epoch": 0.28735632183908044,
      "eval_accuracy": 0.9410178025534975,
      "eval_loss": 0.22612236440181732,
      "eval_runtime": 84.0087,
      "eval_samples_per_second": 66.195,
      "eval_steps_per_second": 2.071,
      "step": 200
    },
    {
      "epoch": 0.3017241379310345,
      "grad_norm": 2.9571115970611572,
      "learning_rate": 1.3965517241379311e-05,
      "loss": 0.2463,
      "step": 210
    },
    {
      "epoch": 0.3160919540229885,
      "grad_norm": 4.041428565979004,
      "learning_rate": 1.367816091954023e-05,
      "loss": 0.2366,
      "step": 220
    },
    {
      "epoch": 0.33045977011494254,
      "grad_norm": 4.486703395843506,
      "learning_rate": 1.339080459770115e-05,
      "loss": 0.2148,
      "step": 230
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 2.6320841312408447,
      "learning_rate": 1.310344827586207e-05,
      "loss": 0.2753,
      "step": 240
    },
    {
      "epoch": 0.35919540229885055,
      "grad_norm": 5.6644606590271,
      "learning_rate": 1.281609195402299e-05,
      "loss": 0.3417,
      "step": 250
    },
    {
      "epoch": 0.3735632183908046,
      "grad_norm": 1.6511152982711792,
      "learning_rate": 1.2528735632183907e-05,
      "loss": 0.2642,
      "step": 260
    },
    {
      "epoch": 0.3879310344827586,
      "grad_norm": 4.530368328094482,
      "learning_rate": 1.2241379310344827e-05,
      "loss": 0.2468,
      "step": 270
    },
    {
      "epoch": 0.40229885057471265,
      "grad_norm": 3.6926238536834717,
      "learning_rate": 1.1954022988505748e-05,
      "loss": 0.2206,
      "step": 280
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 1.600420594215393,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.2136,
      "step": 290
    },
    {
      "epoch": 0.43103448275862066,
      "grad_norm": 1.985127568244934,
      "learning_rate": 1.1379310344827587e-05,
      "loss": 0.2619,
      "step": 300
    },
    {
      "epoch": 0.43103448275862066,
      "eval_accuracy": 0.9370616795540371,
      "eval_loss": 0.22860915958881378,
      "eval_runtime": 84.2384,
      "eval_samples_per_second": 66.015,
      "eval_steps_per_second": 2.066,
      "step": 300
    },
    {
      "epoch": 0.4454022988505747,
      "grad_norm": 3.1862103939056396,
      "learning_rate": 1.1091954022988507e-05,
      "loss": 0.2732,
      "step": 310
    },
    {
      "epoch": 0.45977011494252873,
      "grad_norm": 4.117132186889648,
      "learning_rate": 1.0804597701149427e-05,
      "loss": 0.3037,
      "step": 320
    },
    {
      "epoch": 0.47413793103448276,
      "grad_norm": 5.1875739097595215,
      "learning_rate": 1.0517241379310346e-05,
      "loss": 0.2453,
      "step": 330
    },
    {
      "epoch": 0.4885057471264368,
      "grad_norm": 6.386329174041748,
      "learning_rate": 1.0229885057471264e-05,
      "loss": 0.2653,
      "step": 340
    },
    {
      "epoch": 0.5028735632183908,
      "grad_norm": 1.7993990182876587,
      "learning_rate": 9.942528735632184e-06,
      "loss": 0.2283,
      "step": 350
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 3.1175405979156494,
      "learning_rate": 9.655172413793105e-06,
      "loss": 0.1905,
      "step": 360
    },
    {
      "epoch": 0.5316091954022989,
      "grad_norm": 8.975353240966797,
      "learning_rate": 9.367816091954025e-06,
      "loss": 0.2093,
      "step": 370
    },
    {
      "epoch": 0.5459770114942529,
      "grad_norm": 3.0577778816223145,
      "learning_rate": 9.080459770114942e-06,
      "loss": 0.1787,
      "step": 380
    },
    {
      "epoch": 0.5603448275862069,
      "grad_norm": 4.328051567077637,
      "learning_rate": 8.793103448275862e-06,
      "loss": 0.2322,
      "step": 390
    },
    {
      "epoch": 0.5747126436781609,
      "grad_norm": 0.9283308386802673,
      "learning_rate": 8.505747126436782e-06,
      "loss": 0.1622,
      "step": 400
    },
    {
      "epoch": 0.5747126436781609,
      "eval_accuracy": 0.9496493436432296,
      "eval_loss": 0.19068172574043274,
      "eval_runtime": 84.0795,
      "eval_samples_per_second": 66.14,
      "eval_steps_per_second": 2.069,
      "step": 400
    },
    {
      "epoch": 0.5890804597701149,
      "grad_norm": 1.3235217332839966,
      "learning_rate": 8.218390804597703e-06,
      "loss": 0.1705,
      "step": 410
    },
    {
      "epoch": 0.603448275862069,
      "grad_norm": 1.9981106519699097,
      "learning_rate": 7.93103448275862e-06,
      "loss": 0.3058,
      "step": 420
    },
    {
      "epoch": 0.617816091954023,
      "grad_norm": 1.938803791999817,
      "learning_rate": 7.64367816091954e-06,
      "loss": 0.1661,
      "step": 430
    },
    {
      "epoch": 0.632183908045977,
      "grad_norm": 2.2918221950531006,
      "learning_rate": 7.35632183908046e-06,
      "loss": 0.1445,
      "step": 440
    },
    {
      "epoch": 0.646551724137931,
      "grad_norm": 2.407738447189331,
      "learning_rate": 7.0689655172413796e-06,
      "loss": 0.1513,
      "step": 450
    },
    {
      "epoch": 0.6609195402298851,
      "grad_norm": 0.9417427182197571,
      "learning_rate": 6.781609195402299e-06,
      "loss": 0.1791,
      "step": 460
    },
    {
      "epoch": 0.6752873563218391,
      "grad_norm": 2.083198308944702,
      "learning_rate": 6.49425287356322e-06,
      "loss": 0.2697,
      "step": 470
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 3.0435752868652344,
      "learning_rate": 6.206896551724138e-06,
      "loss": 0.2067,
      "step": 480
    },
    {
      "epoch": 0.7040229885057471,
      "grad_norm": 7.671576023101807,
      "learning_rate": 5.919540229885058e-06,
      "loss": 0.1725,
      "step": 490
    },
    {
      "epoch": 0.7183908045977011,
      "grad_norm": 0.7184632420539856,
      "learning_rate": 5.6321839080459775e-06,
      "loss": 0.1809,
      "step": 500
    },
    {
      "epoch": 0.7183908045977011,
      "eval_accuracy": 0.9503686387340406,
      "eval_loss": 0.1843901425600052,
      "eval_runtime": 84.1266,
      "eval_samples_per_second": 66.103,
      "eval_steps_per_second": 2.068,
      "step": 500
    },
    {
      "epoch": 0.7327586206896551,
      "grad_norm": 0.6268808245658875,
      "learning_rate": 5.344827586206896e-06,
      "loss": 0.2074,
      "step": 510
    },
    {
      "epoch": 0.7471264367816092,
      "grad_norm": 1.672247290611267,
      "learning_rate": 5.057471264367817e-06,
      "loss": 0.2453,
      "step": 520
    },
    {
      "epoch": 0.7614942528735632,
      "grad_norm": 2.963430643081665,
      "learning_rate": 4.770114942528735e-06,
      "loss": 0.1884,
      "step": 530
    },
    {
      "epoch": 0.7758620689655172,
      "grad_norm": 4.566150665283203,
      "learning_rate": 4.482758620689656e-06,
      "loss": 0.2264,
      "step": 540
    },
    {
      "epoch": 0.7902298850574713,
      "grad_norm": 4.0521931648254395,
      "learning_rate": 4.1954022988505746e-06,
      "loss": 0.2109,
      "step": 550
    },
    {
      "epoch": 0.8045977011494253,
      "grad_norm": 1.392334222793579,
      "learning_rate": 3.908045977011495e-06,
      "loss": 0.1705,
      "step": 560
    },
    {
      "epoch": 0.8189655172413793,
      "grad_norm": 3.150330066680908,
      "learning_rate": 3.620689655172414e-06,
      "loss": 0.1994,
      "step": 570
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 2.5023574829101562,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.1776,
      "step": 580
    },
    {
      "epoch": 0.8477011494252874,
      "grad_norm": 0.9464322328567505,
      "learning_rate": 3.0459770114942533e-06,
      "loss": 0.1759,
      "step": 590
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 2.746887683868408,
      "learning_rate": 2.7586206896551725e-06,
      "loss": 0.2312,
      "step": 600
    },
    {
      "epoch": 0.8620689655172413,
      "eval_accuracy": 0.9527063477791764,
      "eval_loss": 0.1774059236049652,
      "eval_runtime": 83.7849,
      "eval_samples_per_second": 66.372,
      "eval_steps_per_second": 2.077,
      "step": 600
    },
    {
      "epoch": 0.8764367816091954,
      "grad_norm": 2.216796875,
      "learning_rate": 2.471264367816092e-06,
      "loss": 0.165,
      "step": 610
    },
    {
      "epoch": 0.8908045977011494,
      "grad_norm": 0.6365155577659607,
      "learning_rate": 2.1839080459770117e-06,
      "loss": 0.1682,
      "step": 620
    },
    {
      "epoch": 0.9051724137931034,
      "grad_norm": 6.395488739013672,
      "learning_rate": 1.896551724137931e-06,
      "loss": 0.167,
      "step": 630
    },
    {
      "epoch": 0.9195402298850575,
      "grad_norm": 2.150803565979004,
      "learning_rate": 1.6091954022988506e-06,
      "loss": 0.1616,
      "step": 640
    },
    {
      "epoch": 0.9339080459770115,
      "grad_norm": 6.6182355880737305,
      "learning_rate": 1.3218390804597702e-06,
      "loss": 0.2008,
      "step": 650
    },
    {
      "epoch": 0.9482758620689655,
      "grad_norm": 0.7391394972801208,
      "learning_rate": 1.0344827586206898e-06,
      "loss": 0.1771,
      "step": 660
    },
    {
      "epoch": 0.9626436781609196,
      "grad_norm": 0.9086595177650452,
      "learning_rate": 7.471264367816093e-07,
      "loss": 0.2257,
      "step": 670
    },
    {
      "epoch": 0.9770114942528736,
      "grad_norm": 7.245183944702148,
      "learning_rate": 4.5977011494252875e-07,
      "loss": 0.2164,
      "step": 680
    },
    {
      "epoch": 0.9913793103448276,
      "grad_norm": 0.8244044184684753,
      "learning_rate": 1.7241379310344828e-07,
      "loss": 0.2353,
      "step": 690
    }
  ],
  "logging_steps": 10,
  "max_steps": 696,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2946312496361472.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
